{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import glob\n",
    "import os.path as osp\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waki-lab/anaconda3/envs/wakilab/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/waki-lab/anaconda3/envs/wakilab/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました\n"
     ]
    }
   ],
   "source": [
    "# 学習済みのVGG-16モデルをロード\n",
    "# VGG-16モデルのインスタンスを生成\n",
    "use_pretrained = True  # 学習済みのパラメータを使用\n",
    "net = models.vgg16(pretrained=use_pretrained)\n",
    "\n",
    "# VGG16の最後の出力層の出力ユニットをアリとハチの2つに付け替える\n",
    "net.classifier[6] = nn.Linear(in_features=4096, out_features=4)\n",
    "\n",
    "# 訓練モードに設定\n",
    "\n",
    "print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorchのネットワークパラメータのロード\n",
    "load_path = '/home/waki-lab/デスクトップ/chiba/学習済み/weights_fine_tuning.pth'\n",
    "#load_weights = torch.load(load_path)\n",
    "#net.load_state_dict(load_weights)\n",
    "# GPU上で保存された重みをCPU上でロードする場合\n",
    "load_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})\n",
    "net.load_state_dict(load_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([172, 154, 3])\n",
      "torch.Size([1, 172, 154, 3])\n",
      "torch.Size([1, 3, 154, 172])\n",
      "tensor([3], device='cuda:0')\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#モデルによって予測ラベルが生成されるかチェック\n",
    "#画像読み込み\n",
    "img=cv2.imread('/home/waki-lab/デスクトップ/chiba/画像/bunnkatu/001,001.jpg')\n",
    "#tensorに変換(型を32ビット浮動小数点数に指定)\n",
    "img=torch.tensor(img,dtype=torch.float32)\n",
    "print(img.size())\n",
    "#0番目にバッチサイズ分の次元を追加\n",
    "img=img.unsqueeze(0)\n",
    "print(img.size())\n",
    "#(バッチサイズ,高さ,幅,色)を(バッチサイズ,色,幅,高さ)に変換\n",
    "img=torch.permute(img,(0,3,2,1))\n",
    "print(img.size())\n",
    "net.to('cuda:0')\n",
    "net.eval() \n",
    "img = img.to('cuda:0')\n",
    "result=net(img)\n",
    "_, preds = torch.max(result, 1)\n",
    "#予測ラベル\n",
    "print(preds)\n",
    "print(preds.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/waki-lab/デスクトップ/chiba/画像/bunnkatu/*.jpg\n"
     ]
    }
   ],
   "source": [
    "#ファイルのパスのリストを制作\n",
    "def make_datapath_list2():\n",
    "\n",
    "    rootpath = \"/home/waki-lab/デスクトップ/chiba/画像/bunnkatu\"\n",
    "    target_path = osp.join(rootpath+'/*.jpg')\n",
    "    print(target_path)\n",
    "\n",
    "    path_list = []  # ここに格納する\n",
    "\n",
    "    # globを利用してサブディレクトリまでファイルパスを取得する\n",
    "    for path in glob.glob(target_path):\n",
    "        path_list.append(path)\n",
    "\n",
    "    return path_list\n",
    "mylist=make_datapath_list2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#フォルダ制作\n",
    "now=str(datetime.datetime.now())\n",
    "new_dir_path='/home/waki-lab/デスクトップ/chiba/グループ分け/'+now\n",
    "os.mkdir(new_dir_path)\n",
    "mori_dir_path=new_dir_path+'/森'\n",
    "os.mkdir(mori_dir_path)\n",
    "umi_dir_path=new_dir_path+'/海'\n",
    "os.mkdir(umi_dir_path)\n",
    "suna_dir_path=new_dir_path+'/砂'\n",
    "os.mkdir(suna_dir_path)\n",
    "siro_dir_path=new_dir_path+'/白'\n",
    "os.mkdir(siro_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let'sグループ分け\n",
    "for path in mylist:\n",
    "    #画像読み込み\n",
    "    IMG=cv2.imread(path)\n",
    "    #tensorに変換(型を32ビット浮動小数点数に指定)\n",
    "    img=torch.tensor(IMG,dtype=torch.float32)\n",
    "    #print(img.size())\n",
    "    #0番目にバッチサイズ分の次元を追加\n",
    "    img=img.unsqueeze(0)\n",
    "    #print(img.size())\n",
    "    #(バッチサイズ,高さ,幅,色)を(バッチサイズ,色,幅,高さ)に変換\n",
    "    img=torch.permute(img,(0,3,2,1))\n",
    "    #print(img.size())\n",
    "    net.to('cuda:0')\n",
    "    net.eval() \n",
    "    img = img.to('cuda:0')\n",
    "    result=net(img)\n",
    "    _, preds = torch.max(result, 1)\n",
    "    #予測ラベル\n",
    "    pred=str(preds.item())\n",
    "    #ラベルを名前に変換\n",
    "    if   pred==str(0):\n",
    "          pred='森'\n",
    "    elif pred==str(1):\n",
    "          pred='砂'\n",
    "    elif pred==str(2):\n",
    "          pred='海'\n",
    "    elif pred==str(3):\n",
    "          pred='白'\n",
    "    #予測ラベルをもとに画像を保存\n",
    "    namepath=path[40:52]\n",
    "    cv2.imwrite('/home/waki-lab/デスクトップ/chiba/グループ分け/'+now+'/'+pred+\"/\"+namepath, IMG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('wakilab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03e90ddc843d6e6e683b0b10ce9c1d2574c565126b2da9dc4e919153435ebb51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
