{"cells":[{"cell_type":"markdown","metadata":{"id":"UA1x5l3QlWqC"},"source":["# 1.3「転移学習」で少量データの分類を実現する方法\n","\n","- 本ファイルでは、学習済みのVGGモデルを使用し、転移学習でアリとハチの画像を分類するモデルを学習します\n","(しませんこれを改造します)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2212,"status":"ok","timestamp":1667232390875,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"7Nk2_bfilWqJ"},"outputs":[],"source":["# パッケージのimport\n","import glob\n","import os.path as osp\n","import random\n","import numpy as np\n","import json\n","from PIL import Image\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torchvision\n","from torchvision import models, transforms\n","\n","import datetime\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667232390875,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"EsQFy7nflWqK"},"outputs":[],"source":["# 乱数のシードを設定\n","torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)"]},{"cell_type":"markdown","metadata":{"id":"e0wuE1LQlWqK"},"source":["# DataSetを作成"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667232390876,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"6PerlS6ilWqK"},"outputs":[],"source":["\n","# 入力画像の前処理をするクラス\n","# 訓練時と推論時で処理が異なる\n","\n","\n","class ImageTransform():\n","    \"\"\"\n","    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n","    画像のサイズをリサイズし、色を標準化する。\n","    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n","\n","\n","    Attributes\n","    ----------\n","    resize : int\n","        リサイズ先の画像の大きさ。\n","    mean : (R, G, B)\n","        各色チャネルの平均値。\n","    std : (R, G, B)\n","        各色チャネルの標準偏差。\n","    \"\"\"\n","\n","    def __init__(self, resize, mean, std):\n","        self.data_transform = {\n","            'train': transforms.Compose([\n","                transforms.Resize(resize),\n","                transforms.ToTensor(),  # テンソルに変換\n","                transforms.Normalize(mean, std)  # 標準化\n","            ]),\n","            'val': transforms.Compose([\n","                #transforms.Resize(resize),  # リサイズ\n","                transforms.ToTensor(),  # テンソルに変換\n","                transforms.Normalize(mean, std)  # 標準化\n","            ])\n","        }\n","\n","    def __call__(self, img, phase='train'):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        phase : 'train' or 'val'\n","            前処理のモードを指定。\n","        \"\"\"\n","        return self.data_transform[phase](img)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667232390876,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"F3gJ3XmJlWqM"},"outputs":[],"source":["\n","\n","# 自分の画像へのファイルパスのリストを作成する\n","\n","\n","def make_datapath_list(phase=\"train\"):\n","    \"\"\"\n","    データのパスを格納したリストを作成する。\n","\n","    Parameters\n","    ----------\n","    phase : 'train' or 'val'\n","        訓練データか検証データかを指定する\n","\n","    Returns\n","    -------\n","    path_list : list\n","        データへのパスを格納したリスト\n","    \"\"\"\n","\n","    rootpath = \"/home/waki-lab/デスクトップ/chiba/画像/dateset3/\"\n","    target_path = osp.join(rootpath+phase+'/**/*.jpg')\n","    print(target_path)\n","\n","    path_list = []  # ここに格納する\n","\n","    # globを利用してサブディレクトリまでファイルパスを取得する\n","    for path in glob.glob(target_path):\n","        path_list.append(path)\n","\n","    return path_list\n","\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'int'>\n","45\n","43\n","47\n"]}],"source":["train_path=len('/home/waki-lab/デスクトップ/chiba/画像/dateset/train')\n","train_path2=len('/home/waki-lab/デスクトップ/chiba/画像/dateset2/train')\n","val_path=len('/home/waki-lab/デスクトップ/chiba/画像/dateset2/val')\n","a=len('/home/waki-lab/デスクトップ/chiba/画像/dateset2/train/海')\n","print(train_path.__class__)\n","print(train_path2)\n","print(val_path)\n","print(a)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667232390876,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"ADiGymTSlWqM"},"outputs":[],"source":["# 自分の画像のDatasetを作成する\n","\n","\n","class HymenopteraDataset(data.Dataset):\n","    \"\"\"\n","    ----------\n","    file_list : リスト\n","        画像のパスを格納したリスト\n","    transform : object\n","        前処理クラスのインスタンス\n","    phase : 'train' or 'test'\n","        学習か訓練かを設定する。\n","    \"\"\"\n","\n","    def __init__(self, file_list, transform=None, phase='train'):\n","        self.file_list = file_list  # ファイルパスのリスト\n","        self.transform = transform  # 前処理クラスのインスタンス\n","        self.phase = phase  # train or valの指定\n","\n","    def __len__(self):\n","        '''画像の枚数を返す'''\n","        return len(self.file_list)\n","\n","    def __getitem__(self, index):\n","        '''\n","        前処理をした画像のTensor形式のデータとラベルを取得\n","        '''\n","\n","        # index番目の画像をロード\n","        img_path = self.file_list[index]\n","        img = Image.open(img_path)  # [高さ][幅][色RGB]\n","\n","        # 画像の前処理を実施\n","        img_transformed = self.transform(\n","            img, self.phase)  # torch.Size([3, 224, 224])\n","\n","        # 画像のラベルをファイル名から抜き出す\n","        if self.phase == \"train\":\n","            #label = img_path[46:50]\n","            label = img_path[train_path+1:train_path+5]\n","        elif self.phase == \"val\":\n","            #label = img_path[44:48]\n","            label = img_path[val_path+1:val_path+5]\n","\n","        # ラベルを数値に変更する\n","        if label == \"mori\":\n","            label = 0\n","        elif label == \"suna\":\n","            label = 1\n","        elif label == \"umii\":\n","            label = 2\n","        elif label == \"siro\":\n","            label = 3\n","\n","        return img_transformed, label\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6M2pUtcklWqN"},"source":["# DataLoaderを作成"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4589,"status":"ok","timestamp":1667232395461,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"lmFNs1-fvgGd","outputId":"17a7fda7-2031-4e90-dd33-6b6e5c5a6952"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/waki-lab/デスクトップ/chiba/画像/dateset3/train/**/*.jpg\n","/home/waki-lab/デスクトップ/chiba/画像/dateset3/val/**/*.jpg\n"]}],"source":["# 自分のの画像へのファイルパスのリストを作成する\n","train_list = make_datapath_list(phase=\"train\")\n","val_list = make_datapath_list(phase=\"val\")\n","\n","# Datasetを作成する\n","size = 150\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","train_dataset = HymenopteraDataset(\n","    file_list=train_list, transform=ImageTransform(size, mean, std), phase='train')\n","\n","val_dataset = HymenopteraDataset(\n","    file_list=val_list, transform=ImageTransform(size, mean, std), phase='val')\n","\n","\n","# DataLoaderを作成する\n","batch_size = 4\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True)\n","\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=True)\n","\n","# 辞書オブジェクトにまとめる\n","dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n"]},{"cell_type":"markdown","metadata":{"id":"kDdKxowclWqN"},"source":["# ネットワークモデルの作成する"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["4af907200908452db183378ee86a1df4","70d7a27cba914664b0062f2c3e66b979","17c30739beed4af7b914424e35cf461e","50712bd877634c02bc4c97e9873e8f8b","34def1820c0f466b87b1319fafdbc8f7","14d42f2c19354ec3967e942f0b403965","46d7b3061d314293b20c5c1aca634d11","4dfc2e4ae83049419ef91cc58f4a0d9e","c47fa60c520e4a73bbc5012c69241f58","5e41502b2764495db9ce17b988b7666b","25921b9df200425b95e04950df40931d"]},"executionInfo":{"elapsed":4294,"status":"ok","timestamp":1667232399750,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"AsfGZ9B7lWqO","outputId":"61d49709-6d1b-4098-a706-c2ce8d8ee97a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/waki-lab/anaconda3/envs/wakilab/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  warnings.warn(\n","/home/waki-lab/anaconda3/envs/wakilab/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました\n"]}],"source":["# 学習済みのVGG-16モデルをロード\n","# VGG-16モデルのインスタンスを生成\n","use_pretrained = True  # 学習済みのパラメータを使用\n","net = models.vgg16(pretrained=use_pretrained)\n","\n","# VGG16の最後の出力層の出力ユニットを4つに付け替える\n","net.classifier[6] = nn.Linear(in_features=4096, out_features=4)\n","\n","# 訓練モードに設定\n","net.train()\n","\n","print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')\n"]},{"cell_type":"markdown","metadata":{"id":"D8rap7ISlWqO"},"source":["# 損失関数を定義"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1667232399750,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"2wiJCU6VlWqO"},"outputs":[],"source":["# 損失関数の設定\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"id":"Kt3ziuoUlWqO"},"source":["# 最適化手法を設定"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1667232399751,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"zWEW8_n0vgGi","outputId":"95dce23b-6a3f-4309-fd29-94120f557a1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["params_to_update_1に格納： features.0.weight\n","params_to_update_1に格納： features.0.bias\n","params_to_update_1に格納： features.2.weight\n","params_to_update_1に格納： features.2.bias\n","params_to_update_1に格納： features.5.weight\n","params_to_update_1に格納： features.5.bias\n","params_to_update_1に格納： features.7.weight\n","params_to_update_1に格納： features.7.bias\n","params_to_update_1に格納： features.10.weight\n","params_to_update_1に格納： features.10.bias\n","params_to_update_1に格納： features.12.weight\n","params_to_update_1に格納： features.12.bias\n","params_to_update_1に格納： features.14.weight\n","params_to_update_1に格納： features.14.bias\n","params_to_update_1に格納： features.17.weight\n","params_to_update_1に格納： features.17.bias\n","params_to_update_1に格納： features.19.weight\n","params_to_update_1に格納： features.19.bias\n","params_to_update_1に格納： features.21.weight\n","params_to_update_1に格納： features.21.bias\n","params_to_update_1に格納： features.24.weight\n","params_to_update_1に格納： features.24.bias\n","params_to_update_1に格納： features.26.weight\n","params_to_update_1に格納： features.26.bias\n","params_to_update_1に格納： features.28.weight\n","params_to_update_1に格納： features.28.bias\n","params_to_update_2に格納： classifier.0.weight\n","params_to_update_2に格納： classifier.0.bias\n","params_to_update_2に格納： classifier.3.weight\n","params_to_update_2に格納： classifier.3.bias\n","params_to_update_3に格納： classifier.6.weight\n","params_to_update_3に格納： classifier.6.bias\n"]}],"source":["# ファインチューニングで学習させるパラメータを、変数params_to_updateの1～3に格納する\n","\n","params_to_update_1 = []\n","params_to_update_2 = []\n","params_to_update_3 = []\n","\n","# 学習させる層のパラメータ名を指定\n","update_param_names_1 = [\"features\"]\n","update_param_names_2 = [\"classifier.0.weight\",\n","                        \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n","update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n","\n","# パラメータごとに各リストに格納する\n","for name, param in net.named_parameters():\n","    if update_param_names_1[0] in name:\n","        param.requires_grad = True\n","        params_to_update_1.append(param)\n","        print(\"params_to_update_1に格納：\", name)\n","\n","    elif name in update_param_names_2:\n","        param.requires_grad = True\n","        params_to_update_2.append(param)\n","        print(\"params_to_update_2に格納：\", name)\n","\n","    elif name in update_param_names_3:\n","        param.requires_grad = True\n","        params_to_update_3.append(param)\n","        print(\"params_to_update_3に格納：\", name)\n","\n","    else:\n","        param.requires_grad = False\n","        print(\"勾配計算なし。学習しない：\", name)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1667232399751,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"-ZIFyQP-vgGi"},"outputs":[],"source":["# 最適化手法の設定\n","optimizer = optim.SGD([\n","    {'params': params_to_update_1, 'lr': 1e-4},\n","    {'params': params_to_update_2, 'lr': 5e-4},\n","    {'params': params_to_update_3, 'lr': 1e-3}\n","], momentum=0.9)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"2eZpP_IlvgGj"},"source":["# 学習・検証を実施"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1667232399751,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"PQQZFE20vgGj"},"outputs":[],"source":["# モデルを学習させる関数を作成\n","\n","\n","def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n","\n","    # 初期設定\n","    # GPUが使えるかを確認\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"使用デバイス：\", device)\n","\n","    # ネットワークをGPUへ\n","    net.to(device)\n","\n","    # ネットワークがある程度固定であれば、高速化させる\n","    torch.backends.cudnn.benchmark = True\n","\n","    # epochのループ\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-------------')\n","\n","        # epochごとの訓練と検証のループ\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                net.train()  # モデルを訓練モードに\n","            else:\n","                net.eval()   # モデルを検証モードに\n","\n","            epoch_loss = 0.0  # epochの損失和\n","            epoch_corrects = 0  # epochの正解数\n","\n","            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n","            if (epoch == 0) and (phase == 'train'):\n","                continue\n","\n","            # データローダーからミニバッチを取り出すループ\n","            for inputs, labels in tqdm(dataloaders_dict[phase]):\n","            \n","                # GPUが使えるならGPUにデータを送る\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # optimizerを初期化\n","                optimizer.zero_grad()\n","\n","                # 順伝搬（forward）計算\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = net(inputs)\n","                    loss = criterion(outputs, labels)  # 損失を計算\n","                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n","\n","                    # 訓練時はバックプロパゲーション\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                    # 結果の計算\n","                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n","                    # 正解数の合計を更新\n","                    epoch_corrects += torch.sum(preds == labels.data)\n","\n","            # epochごとのlossと正解率を表示\n","            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.double(\n","            ) / len(dataloaders_dict[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","    return epoch_acc\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":464498,"status":"ok","timestamp":1667232864230,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"ylxR7x8rvgGk","outputId":"2d1445a9-aad7-4340-ade7-ce7ccef9924f"},"outputs":[{"name":"stdout","output_type":"stream","text":["使用デバイス： cuda:0\n","Epoch 1/10\n","-------------\n"]},{"name":"stderr","output_type":"stream","text":[" 84%|████████▎ | 107/128 [00:03<00:00, 30.93it/s]\n"]},{"ename":"RuntimeError","evalue":"stack expects each tensor to be equal size, but got [3, 172, 223] at entry 0 and [3, 172, 154] at entry 1","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32mセル22 を /home/waki-lab/デスクトップ/chiba/卒検/モデル作成.ipynb\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/waki-lab/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/chiba/%E5%8D%92%E6%A4%9C/%E3%83%A2%E3%83%87%E3%83%AB%E4%BD%9C%E6%88%90.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 学習・検証を実行する\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/waki-lab/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/chiba/%E5%8D%92%E6%A4%9C/%E3%83%A2%E3%83%87%E3%83%AB%E4%BD%9C%E6%88%90.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m num_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/waki-lab/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/chiba/%E5%8D%92%E6%A4%9C/%E3%83%A2%E3%83%87%E3%83%AB%E4%BD%9C%E6%88%90.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m acc\u001b[39m=\u001b[39mtrain_model(net, dataloaders_dict, criterion, optimizer, num_epochs\u001b[39m=\u001b[39;49mnum_epochs)\n","\u001b[1;32mセル22 を /home/waki-lab/デスクトップ/chiba/卒検/モデル作成.ipynb\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, dataloaders_dict, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/waki-lab/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/chiba/%E5%8D%92%E6%A4%9C/%E3%83%A2%E3%83%87%E3%83%AB%E4%BD%9C%E6%88%90.ipynb#X30sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/waki-lab/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/chiba/%E5%8D%92%E6%A4%9C/%E3%83%A2%E3%83%87%E3%83%AB%E4%BD%9C%E6%88%90.ipynb#X30sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# データローダーからミニバッチを取り出すループ\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/waki-lab/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/chiba/%E5%8D%92%E6%A4%9C/%E3%83%A2%E3%83%87%E3%83%AB%E4%BD%9C%E6%88%90.ipynb#X30sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m tqdm(dataloaders_dict[phase]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/waki-lab/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/chiba/%E5%8D%92%E6%A4%9C/%E3%83%A2%E3%83%87%E3%83%AB%E4%BD%9C%E6%88%90.ipynb#X30sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/waki-lab/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/chiba/%E5%8D%92%E6%A4%9C/%E3%83%A2%E3%83%87%E3%83%AB%E4%BD%9C%E6%88%90.ipynb#X30sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m# GPUが使えるならGPUにデータを送る\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/waki-lab/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/chiba/%E5%8D%92%E6%A4%9C/%E3%83%A2%E3%83%87%E3%83%AB%E4%BD%9C%E6%88%90.ipynb#X30sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/waki-lab/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/chiba/%E5%8D%92%E6%A4%9C/%E3%83%A2%E3%83%87%E3%83%AB%E4%BD%9C%E6%88%90.ipynb#X30sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n","File \u001b[0;32m~/anaconda3/envs/wakilab/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/wakilab/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/anaconda3/envs/wakilab/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/anaconda3/envs/wakilab/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n","File \u001b[0;32m~/anaconda3/envs/wakilab/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n","File \u001b[0;32m~/anaconda3/envs/wakilab/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n","File \u001b[0;32m~/anaconda3/envs/wakilab/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    140\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[1;32m    142\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m    143\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    145\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 172, 223] at entry 0 and [3, 172, 154] at entry 1"]}],"source":["# 学習・検証を実行する\n","num_epochs=10\n","acc=train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n"]},{"cell_type":"markdown","metadata":{"id":"08s8rTAWvgGk"},"source":["# 学習したネットワークを保存・ロード"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2477,"status":"ok","timestamp":1667232866688,"user":{"displayName":"歩夢","userId":"00133174985362695994"},"user_tz":-540},"id":"b3B2n8lhvgGl"},"outputs":[],"source":["now=datetime.datetime.now()\n","# PyTorchのネットワークパラメータの保存\n","save_path = '/home/waki-lab/デスクトップ/chiba/学習済み/'+str(now)+\"aaaaa\"+str(acc.item())+'Acc.pth'\n","torch.save(net.state_dict(), save_path)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"13NtjVEsfDSGT2gwrQgsAXkuq0XOf4or3","timestamp":1667231758864},{"file_id":"1RQNFgrZEvZe2LRdxBImCTTt2zVTzUCLx","timestamp":1667231270350},{"file_id":"1-6XRug1BCBKCKMOGi-wCz9-v83-B6SBM","timestamp":1667207603952}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 ('wakilab')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"03e90ddc843d6e6e683b0b10ce9c1d2574c565126b2da9dc4e919153435ebb51"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"14d42f2c19354ec3967e942f0b403965":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17c30739beed4af7b914424e35cf461e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dfc2e4ae83049419ef91cc58f4a0d9e","max":553433881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c47fa60c520e4a73bbc5012c69241f58","value":553433881}},"25921b9df200425b95e04950df40931d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34def1820c0f466b87b1319fafdbc8f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46d7b3061d314293b20c5c1aca634d11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4af907200908452db183378ee86a1df4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70d7a27cba914664b0062f2c3e66b979","IPY_MODEL_17c30739beed4af7b914424e35cf461e","IPY_MODEL_50712bd877634c02bc4c97e9873e8f8b"],"layout":"IPY_MODEL_34def1820c0f466b87b1319fafdbc8f7"}},"4dfc2e4ae83049419ef91cc58f4a0d9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50712bd877634c02bc4c97e9873e8f8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e41502b2764495db9ce17b988b7666b","placeholder":"​","style":"IPY_MODEL_25921b9df200425b95e04950df40931d","value":" 528M/528M [00:02&lt;00:00, 204MB/s]"}},"5e41502b2764495db9ce17b988b7666b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70d7a27cba914664b0062f2c3e66b979":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14d42f2c19354ec3967e942f0b403965","placeholder":"​","style":"IPY_MODEL_46d7b3061d314293b20c5c1aca634d11","value":"100%"}},"c47fa60c520e4a73bbc5012c69241f58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
